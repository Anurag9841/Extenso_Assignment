[2024-06-10T08:43:27.662+0000] {processor.py:161} INFO - Started process (PID=171) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:43:27.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:43:27.715+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:43:27.714+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:43:28.781+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:43:28.748+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from read_data import read_datas
ModuleNotFoundError: No module named 'read_data'
[2024-06-10T08:43:28.855+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:43:28.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.420 seconds
[2024-06-10T08:43:59.633+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:43:59.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:43:59.750+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:43:59.698+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:44:00.293+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:44:00.269+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from read_data import read_datas
ModuleNotFoundError: No module named 'read_data'
[2024-06-10T08:44:00.295+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:44:00.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.153 seconds
[2024-06-10T08:44:30.915+0000] {processor.py:161} INFO - Started process (PID=193) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:44:30.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:44:30.930+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:44:30.929+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:44:31.249+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:44:31.219+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from read_data import read_datas
ModuleNotFoundError: No module named 'read_data'
[2024-06-10T08:44:31.252+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:44:31.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.529 seconds
[2024-06-10T08:45:02.770+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:45:02.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:45:03.140+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:45:03.119+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:45:05.153+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:45:05.111+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from read_data import read_datas
ModuleNotFoundError: No module named 'read_data'
[2024-06-10T08:45:05.162+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:45:06.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 3.845 seconds
[2024-06-10T08:45:38.416+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:45:38.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:45:38.631+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:45:38.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:45:40.651+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:45:40.621+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from read_data import read_datas
ModuleNotFoundError: No module named 'read_data'
[2024-06-10T08:45:40.661+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:45:41.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 3.551 seconds
[2024-06-10T08:46:11.667+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:46:11.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:46:11.862+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:46:11.861+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:46:11.987+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:46:11.977+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from read_data import read_datas
ModuleNotFoundError: No module named 'read_data'
[2024-06-10T08:46:11.991+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:46:12.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.371 seconds
[2024-06-10T08:46:42.583+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:46:42.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:46:42.607+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:46:42.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:46:42.765+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:46:42.751+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from read_data import read_datas
ModuleNotFoundError: No module named 'read_data'
[2024-06-10T08:46:42.767+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:46:42.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.432 seconds
[2024-06-10T08:47:13.249+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:47:13.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:47:13.259+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:47:13.258+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:52:42.857+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:52:42.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:52:42.883+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:52:42.867+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:52:43.014+0000] {logging_mixin.py:188} WARNING - /opt/airflow/python_files/aggregate_function.py:6 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:52:43.377+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:52:43.378+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:52:43.365+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:52:43.379+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:52:43.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.570 seconds
[2024-06-10T08:53:13.979+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:53:13.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:53:14.002+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:53:14.000+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:53:14.988+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:53:14.992+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:53:14.955+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:53:15.006+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:53:15.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.262 seconds
[2024-06-10T08:53:45.474+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:53:45.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:53:45.477+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:53:45.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:53:45.815+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:53:45.818+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:53:45.798+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:53:45.824+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:53:45.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.399 seconds
[2024-06-10T08:54:15.935+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:54:15.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:54:15.940+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:54:15.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:54:16.237+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:54:16.238+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:54:16.220+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:54:16.240+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:54:16.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.336 seconds
[2024-06-10T08:54:46.319+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:54:46.320+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:54:46.322+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:54:46.322+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:54:46.564+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:54:46.565+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:54:46.552+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:54:46.567+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:54:46.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.276 seconds
[2024-06-10T08:55:16.772+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:55:16.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:55:16.776+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:55:16.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:55:17.026+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:55:17.027+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:55:17.016+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:55:17.028+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:55:17.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.288 seconds
[2024-06-10T08:55:47.290+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:55:47.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:55:47.312+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:55:47.311+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:55:48.034+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:55:48.036+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:55:47.979+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:55:48.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:55:48.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.788 seconds
[2024-06-10T08:56:18.158+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:56:18.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:56:18.161+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:56:18.162+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:56:18.407+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:56:18.408+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:56:18.400+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:56:18.410+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:56:18.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.279 seconds
[2024-06-10T08:56:48.654+0000] {processor.py:161} INFO - Started process (PID=320) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:56:48.658+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:56:48.664+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:56:48.663+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:56:49.286+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:56:49.288+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:56:49.267+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:56:49.293+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:56:49.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.689 seconds
[2024-06-10T08:57:19.558+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:57:19.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:57:19.560+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:57:19.560+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:57:19.828+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:57:19.830+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:57:19.816+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:57:19.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:57:19.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.310 seconds
[2024-06-10T08:57:50.073+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:57:50.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:57:50.078+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:57:50.078+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:57:50.353+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:57:50.354+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:57:50.345+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:57:50.355+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:57:50.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.314 seconds
[2024-06-10T08:58:20.561+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:58:20.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:58:20.564+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:58:20.564+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:58:20.793+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:58:20.795+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:58:20.784+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:58:20.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:58:20.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.264 seconds
[2024-06-10T08:58:50.980+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:58:50.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:58:50.983+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:58:50.982+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:58:51.223+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:58:51.224+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:58:51.210+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:58:51.226+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:58:51.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.284 seconds
[2024-06-10T08:59:21.455+0000] {processor.py:161} INFO - Started process (PID=425) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:59:21.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:59:21.458+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:59:21.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:59:21.765+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:59:21.767+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:59:21.749+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:59:21.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:59:21.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.344 seconds
[2024-06-10T08:59:51.983+0000] {processor.py:161} INFO - Started process (PID=444) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:59:51.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T08:59:51.986+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:59:51.986+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:59:52.256+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T08:59:52.257+0000] {logging_mixin.py:188} INFO - [2024-06-10T08:59:52.246+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T08:59:52.258+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T08:59:52.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.304 seconds
[2024-06-10T09:00:22.515+0000] {processor.py:161} INFO - Started process (PID=463) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:00:22.516+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:00:22.519+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:00:22.518+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:00:22.950+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:00:22.963+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:00:22.877+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:00:22.967+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:00:23.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.573 seconds
[2024-06-10T09:00:53.311+0000] {processor.py:161} INFO - Started process (PID=488) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:00:53.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:00:53.314+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:00:53.314+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:00:53.549+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:00:53.550+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:00:53.536+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:00:53.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:00:53.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.275 seconds
[2024-06-10T09:01:23.771+0000] {processor.py:161} INFO - Started process (PID=507) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:01:23.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:01:23.774+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:01:23.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:01:24.006+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:01:24.007+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:01:23.999+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:01:24.008+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:01:24.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.264 seconds
[2024-06-10T09:01:54.255+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:01:54.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:01:54.265+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:01:54.264+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:01:54.787+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:01:54.790+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:01:54.777+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:01:54.792+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:01:54.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.581 seconds
[2024-06-10T09:02:25.169+0000] {processor.py:161} INFO - Started process (PID=546) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:02:25.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:02:25.175+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:02:25.174+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:02:25.726+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:02:25.728+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:02:25.706+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:02:25.731+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:02:25.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.614 seconds
[2024-06-10T09:02:55.974+0000] {processor.py:161} INFO - Started process (PID=565) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:02:55.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:02:55.977+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:02:55.976+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:02:56.202+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:02:56.203+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:02:56.195+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:02:56.204+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:02:56.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.259 seconds
[2024-06-10T09:03:26.453+0000] {processor.py:161} INFO - Started process (PID=584) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:03:26.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:03:26.456+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:03:26.456+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:03:26.699+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:03:26.701+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:03:26.692+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:03:26.702+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:03:26.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.280 seconds
[2024-06-10T09:03:56.911+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:03:56.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:03:56.914+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:03:56.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:03:57.253+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:03:57.256+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:03:57.231+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:03:57.259+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:03:57.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.400 seconds
[2024-06-10T09:04:27.511+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:04:27.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:04:27.516+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:04:27.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:04:27.741+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:04:27.742+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:04:27.735+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:04:27.743+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:04:27.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.257 seconds
[2024-06-10T09:04:57.914+0000] {processor.py:161} INFO - Started process (PID=641) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:04:57.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:04:57.916+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:04:57.916+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:04:58.139+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:04:58.140+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:04:58.131+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:04:58.141+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:04:58.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.250 seconds
[2024-06-10T09:05:28.334+0000] {processor.py:161} INFO - Started process (PID=660) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:05:28.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:05:28.337+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:05:28.337+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:05:28.575+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:05:28.576+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:05:28.567+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:05:28.577+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:05:28.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.266 seconds
[2024-06-10T09:05:58.818+0000] {processor.py:161} INFO - Started process (PID=679) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:05:58.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:05:58.821+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:05:58.820+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:05:59.138+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:05:59.140+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:05:59.120+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:05:59.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:05:59.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.375 seconds
[2024-06-10T09:06:29.522+0000] {processor.py:161} INFO - Started process (PID=698) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:06:29.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:06:29.526+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:06:29.525+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:06:29.848+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:06:29.849+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:06:29.836+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:06:29.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:06:29.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.376 seconds
[2024-06-10T09:07:00.175+0000] {processor.py:161} INFO - Started process (PID=717) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:07:00.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:07:00.188+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:07:00.188+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:07:00.707+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:07:00.710+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:07:00.690+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:07:00.716+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:07:00.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.636 seconds
[2024-06-10T09:07:31.184+0000] {processor.py:161} INFO - Started process (PID=736) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:07:31.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:07:31.187+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:07:31.187+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:07:31.518+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:07:31.519+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:07:31.503+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:07:31.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:07:31.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.384 seconds
[2024-06-10T09:08:01.933+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:08:01.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:08:01.941+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:08:01.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:08:02.266+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:08:02.267+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:08:02.256+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:08:02.271+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:08:02.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.379 seconds
[2024-06-10T09:08:32.569+0000] {processor.py:161} INFO - Started process (PID=774) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:08:32.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:08:32.573+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:08:32.572+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:08:32.887+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:08:32.888+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:08:32.861+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:08:32.890+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:08:32.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.357 seconds
[2024-06-10T09:09:03.131+0000] {processor.py:161} INFO - Started process (PID=793) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:09:03.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:09:03.136+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:09:03.136+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:09:03.482+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:09:03.484+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:09:03.469+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:09:03.486+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:09:03.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.408 seconds
[2024-06-10T09:09:33.795+0000] {processor.py:161} INFO - Started process (PID=812) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:09:33.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:09:33.800+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:09:33.799+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:09:34.136+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:09:34.141+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:09:34.099+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:09:34.146+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:09:34.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.441 seconds
[2024-06-10T09:10:04.515+0000] {processor.py:161} INFO - Started process (PID=831) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:10:04.516+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T09:10:04.519+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:10:04.518+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:10:04.788+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T09:10:04.789+0000] {logging_mixin.py:188} INFO - [2024-06-10T09:10:04.778+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T09:10:04.790+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T09:10:04.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.313 seconds
[2024-06-10T10:38:53.122+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:38:53.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:38:53.129+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:38:53.126+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:38:53.249+0000] {logging_mixin.py:188} WARNING - /opt/airflow/python_files/aggregate_function.py:6 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:38:53.607+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:38:53.608+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:38:53.602+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:38:53.609+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:38:53.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.522 seconds
[2024-06-10T10:39:24.016+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:39:24.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:39:24.033+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:39:24.031+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:39:24.320+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:39:24.321+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:39:24.312+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:39:24.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:39:24.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.342 seconds
[2024-06-10T10:39:54.589+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:39:54.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:39:54.591+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:39:54.591+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:39:54.825+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:39:54.826+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:39:54.814+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:39:54.827+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:39:54.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.264 seconds
[2024-06-10T10:40:25.073+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:40:25.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:40:25.077+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:40:25.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:40:25.356+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:40:25.357+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:40:25.347+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:40:25.359+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:40:25.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.322 seconds
[2024-06-10T10:40:55.651+0000] {processor.py:161} INFO - Started process (PID=243) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:40:55.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:40:55.654+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:40:55.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:40:56.018+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:40:56.019+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:40:56.011+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:40:56.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:40:56.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.408 seconds
[2024-06-10T10:41:26.358+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:41:26.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:41:26.363+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:41:26.363+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:41:26.646+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:41:26.647+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:41:26.636+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:41:26.649+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:41:26.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.334 seconds
[2024-06-10T10:41:57.008+0000] {processor.py:161} INFO - Started process (PID=281) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:41:57.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:41:57.015+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:41:57.014+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:41:57.316+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:41:57.317+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:41:57.299+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:41:57.318+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:41:57.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.398 seconds
[2024-06-10T10:42:27.641+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:42:27.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:42:27.644+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:42:27.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:42:27.889+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:42:27.889+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:42:27.880+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:42:27.891+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:42:27.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.279 seconds
[2024-06-10T10:42:58.161+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:42:58.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:42:58.167+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:42:58.166+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:42:58.617+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:42:58.619+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:42:58.603+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:42:58.622+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:42:58.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.505 seconds
[2024-06-10T10:43:28.872+0000] {processor.py:161} INFO - Started process (PID=338) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:43:28.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:43:28.875+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:43:28.874+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:43:29.098+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:43:29.098+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:43:29.087+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:43:29.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:43:29.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.257 seconds
[2024-06-10T10:43:59.185+0000] {processor.py:161} INFO - Started process (PID=358) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:43:59.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:43:59.188+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:43:59.188+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:43:59.423+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:43:59.424+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:43:59.412+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:43:59.425+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:43:59.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.272 seconds
[2024-06-10T10:46:49.508+0000] {processor.py:161} INFO - Started process (PID=170) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:46:49.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:46:49.520+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:46:49.517+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:46:50.093+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:46:50.098+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:46:50.081+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:46:50.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:46:50.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.696 seconds
[2024-06-10T10:47:20.792+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:47:20.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:47:20.816+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:47:20.813+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:47:21.893+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:47:21.895+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:47:21.870+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:47:21.903+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:47:22.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.921 seconds
[2024-06-10T10:47:53.368+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:47:53.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:47:53.403+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:47:53.398+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:47:54.695+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:47:54.702+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:47:54.646+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:47:54.708+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:47:54.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.667 seconds
[2024-06-10T10:48:25.811+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:48:25.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:48:25.854+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:48:25.850+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:48:27.375+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:48:27.380+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:48:27.330+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:48:27.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:48:27.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.920 seconds
[2024-06-10T10:48:57.990+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:48:57.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:48:58.002+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:48:58.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:48:58.414+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:48:58.415+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:48:58.402+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:48:58.417+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:48:58.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.533 seconds
[2024-06-10T10:49:28.840+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:49:28.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:49:28.857+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:49:28.856+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:49:29.487+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:49:29.537+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:49:29.451+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:49:29.542+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:49:29.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.833 seconds
[2024-06-10T10:50:00.271+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:50:00.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:50:00.305+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:50:00.303+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:50:01.675+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:50:01.678+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:50:01.640+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:50:01.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:50:01.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.526 seconds
[2024-06-10T10:50:32.018+0000] {processor.py:161} INFO - Started process (PID=297) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:50:32.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:50:32.023+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:50:32.022+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:57:32.615+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:57:32.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T10:57:32.618+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:57:32.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:57:32.991+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T10:57:32.995+0000] {logging_mixin.py:188} INFO - [2024-06-10T10:57:32.962+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T10:57:32.999+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T10:57:33.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.429 seconds
[2024-06-10T11:28:48.866+0000] {processor.py:161} INFO - Started process (PID=171) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:28:48.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:28:48.901+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:28:48.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:28:50.443+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:28:50.444+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:28:50.434+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:28:50.445+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:28:50.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.867 seconds
[2024-06-10T11:29:21.806+0000] {processor.py:161} INFO - Started process (PID=193) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:29:21.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:29:21.884+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:29:21.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:29:28.457+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:29:28.468+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:29:28.261+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:29:28.489+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:29:28.967+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 7.338 seconds
[2024-06-10T11:29:59.745+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:29:59.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:29:59.823+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:29:59.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:30:03.375+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:30:03.386+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:30:03.248+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:30:03.391+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:30:03.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 4.088 seconds
[2024-06-10T11:30:34.496+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:30:34.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:30:34.537+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:30:34.527+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:30:37.842+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:30:37.852+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:30:37.789+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:30:37.856+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:30:38.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 3.739 seconds
[2024-06-10T11:31:08.869+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:31:08.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:31:08.901+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:31:08.900+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:31:11.027+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:31:11.034+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:31:10.966+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:31:11.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:31:11.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 2.436 seconds
[2024-06-10T11:31:41.755+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:31:41.768+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:31:41.777+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:31:41.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:31:42.270+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:31:42.272+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:31:42.254+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:31:42.273+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:31:42.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.591 seconds
[2024-06-10T11:32:12.601+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:32:12.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:32:12.614+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:32:12.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:32:13.229+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:32:13.231+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:32:13.209+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:32:13.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:32:13.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.703 seconds
[2024-06-10T11:32:43.518+0000] {processor.py:161} INFO - Started process (PID=330) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:32:43.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:32:43.551+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:32:43.547+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:32:44.194+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:32:44.196+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:32:44.170+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:32:44.198+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:32:44.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 0.831 seconds
[2024-06-10T11:33:14.511+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:33:14.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:33:14.515+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:33:14.515+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:50:27.589+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:50:27.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:50:27.626+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:50:27.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:50:29.147+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:50:29.152+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:50:29.120+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:50:29.158+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:50:29.343+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.893 seconds
[2024-06-10T11:50:59.900+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:50:59.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:50:59.951+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:50:59.941+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:51:01.170+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:51:01.172+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:51:01.139+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:51:01.177+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:51:01.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.594 seconds
[2024-06-10T11:51:31.720+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:51:31.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:51:31.915+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:51:31.913+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:51:32.748+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:51:32.749+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:51:32.736+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:51:32.751+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:51:32.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 1.150 seconds
[2024-06-10T11:52:04.467+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:52:04.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:52:04.644+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:52:04.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:52:10.287+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:52:10.296+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:52:10.141+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:52:10.310+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:52:10.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 6.961 seconds
[2024-06-10T11:52:43.325+0000] {processor.py:161} INFO - Started process (PID=266) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:52:43.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:52:43.824+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:52:43.805+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:52:47.460+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\s'
[2024-06-10T11:52:47.475+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:52:47.233+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/Entity_matching_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/Entity_matching_dag.py", line 6, in <module>
    from final_table import main
  File "/opt/airflow/python_files/final_table.py", line 1, in <module>
    from aggregate_function import table,config,get_start_last_transaction_date,new_data,Schema,df
  File "/opt/airflow/python_files/aggregate_function.py", line 6, in <module>
    spark = SparkSession.builder.appName("spark_dataframe_py").config("spark.jars", "C:\spark-3.5.1-bin-hadoop3\jars\mysql-connector-j-8.4.0.jar").getOrCreate()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 107, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
[2024-06-10T11:52:47.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:52:50.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/Entity_matching_dag.py took 7.720 seconds
[2024-06-10T11:53:24.615+0000] {processor.py:161} INFO - Started process (PID=288) to work on /opt/airflow/dags/Entity_matching_dag.py
[2024-06-10T11:53:24.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/Entity_matching_dag.py for tasks to queue
[2024-06-10T11:53:25.051+0000] {logging_mixin.py:188} INFO - [2024-06-10T11:53:24.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/Entity_matching_dag.py
