{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-23T08:32:47.671565Z",
     "start_time": "2024-06-23T08:32:47.048292Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import *\n",
    "import pymysql"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T08:32:47.687193Z",
     "start_time": "2024-06-23T08:32:47.671565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "connection = pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        user='root',\n",
    "        password='root',\n",
    "        database='extenso_config'\n",
    "    )"
   ],
   "id": "be3bba34b6742786",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T08:32:54.192037Z",
     "start_time": "2024-06-23T08:32:47.687193Z"
    }
   },
   "cell_type": "code",
   "source": "spark = SparkSession.builder.appName(\"hadoop_add_file\").config(\"spark.jars\", \"C:\\spark-3.5.1-bin-hadoop3\\jars\\mysql-connector-j-8.4.0.jar\").getOrCreate()",
   "id": "eae31355b51169b7",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T08:32:54.207672Z",
     "start_time": "2024-06-23T08:32:54.192037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"jdbc:mysql://localhost:3306/extenso_config\"\n",
    "properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"driver\": \"com.mysql.jdbc.Driver\"\n",
    "}"
   ],
   "id": "dfbf35621e06b01e",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T08:32:54.223694Z",
     "start_time": "2024-06-23T08:32:54.208179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hdfs_file_upload(url,properties,table_name):\n",
    "     df = spark.read.jdbc(url=url, table=table_name, properties=properties)\n",
    "     for i in range(df.count()):\n",
    "         active_status = df.select(\"active_status\").collect()\n",
    "         status = active_status[i]['active_status']\n",
    "         if status == False:\n",
    "             with connection.cursor() as cursor:\n",
    "                 update_query = f'UPDATE extenso_config.my_config set active_status = 1 where id = {i + 1}'\n",
    "                 cursor.execute(update_query)\n",
    "             schemas = df.select(\"schemaName\").collect()\n",
    "             schema = schemas[i][\"schemaName\"]\n",
    "             tables_name = df.select(\"tableName\").collect()\n",
    "             name = tables_name[i]['tableName']\n",
    "             locations = df.select(\"location\").collect()\n",
    "             location = locations[i]['location']\n",
    "             hdfs_file_name = df.select(\"hdfs_file_name\").collect()\n",
    "             file_name = hdfs_file_name[i]['hdfs_file_name']\n",
    "             jdbc_url = f\"jdbc:mysql://localhost:3306/{schema}\"\n",
    "             connection_properties = {\"user\":\"root\", \"password\":\"root\", \"driver\":\"com.mysql.jdbc.Driver\"}\n",
    "             dfs = spark.read.jdbc(url=jdbc_url, table = name, properties=connection_properties)\n",
    "             hdfs_path = f'{location}/{file_name}'\n",
    "             dfs.write.mode(\"overwrite\").parquet(hdfs_path)\n",
    "             \n",
    "                 "
   ],
   "id": "9b50d80057dc3501",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T08:33:09.641750Z",
     "start_time": "2024-06-23T08:32:54.223694Z"
    }
   },
   "cell_type": "code",
   "source": "hdfs_file_upload(url,properties,\"my_config\")",
   "id": "7c332538eca00568",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T08:33:12.504340Z",
     "start_time": "2024-06-23T08:33:11.811199Z"
    }
   },
   "cell_type": "code",
   "source": "data = spark.read.parquet('hdfs://localhost:19000/anurag/sample_data')",
   "id": "daef784b8a42b940",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T08:33:16.308867Z",
     "start_time": "2024-06-23T08:33:12.628963Z"
    }
   },
   "cell_type": "code",
   "source": "data.show()",
   "id": "8704284c28f0b537",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "c4e5cedf6c02700a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
